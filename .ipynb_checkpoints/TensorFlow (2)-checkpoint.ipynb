{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92678e68-a6ab-467d-a724-459e45d18636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_hdf('data.h5')\n",
    "train_data=data[data['is_train']==True]\n",
    "test_data = data[data['is_train']==False]\n",
    "Y = train_data['class']\n",
    "X = train_data.iloc[:, [1, 2, 3, 24, 37, 47, 49, 51, 56, 58]].to_numpy()\n",
    "X_test = test_data.iloc[:, [1, 2, 3, 24, 37, 47, 49, 51, 56, 58]]\n",
    "Y_test = test_data['class']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b410847-0b23-449d-bf78-9e43b8f75a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import conifer ydf converter\n",
      "/opt/conda/envs/fpga-env/lib/python3.10/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'underscore_attrs_are_private' has been removed\n",
      "  warnings.warn(message, UserWarning)\n",
      "/opt/conda/envs/fpga-env/lib/python3.10/site-packages/pynqutils/build_utils/xsa_parser.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/opt/conda/envs/fpga-env/lib/python3.10/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'underscore_attrs_are_private' has been removed\n",
      "  warnings.warn(message, UserWarning)\n",
      "2025-09-05 09:24:38.828268: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-05 09:24:38.830538: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-05 09:24:38.863742: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-05 09:24:38.863804: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-05 09:24:38.864725: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-05 09:24:38.870502: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-05 09:24:38.871478: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-05 09:24:39.860220: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# INFN-MIB Cloud Environment Paths\n",
    "import os\n",
    "import sys\n",
    "import sysconfig\n",
    "import pybind11\n",
    "\n",
    "# Add Viavado bin\n",
    "os.environ['PATH'] = '/opt/tools/Xilinx/Vivado/2023.2/bin:' + os.environ['PATH']\n",
    "\n",
    "# Pynq-Z2 files\n",
    "os.environ[\"BOARD_REPO_PATHS\"] = \"/opt/tools/Xilinx/Vivado/2023.2/data/boards/board_files/pynq-z2\"\n",
    "\n",
    "# Add HLS bin\n",
    "os.environ['PATH'] = '/opt/tools/Xilinx/Vitis_HLS/2023.2/bin:' + os.environ['PATH']\n",
    "os.environ['XILINX_HLS'] = '/opt/tools/Xilinx/Vitis_HLS/2023.2/'\n",
    "\n",
    "# Use system compilers\n",
    "os.environ['CC'] = '/usr/bin/gcc'\n",
    "os.environ['CXX'] = '/usr/bin/g++'\n",
    "os.environ['LD'] = '/usr/bin/ld'\n",
    "\n",
    "## Python bindings\n",
    "# Force shell subprocesses to use the right python\n",
    "env_path = os.environ['PATH']\n",
    "correct_python_dir = os.path.dirname(sys.executable)\n",
    "os.environ['PATH'] = f\"{correct_python_dir}:{env_path}\"\n",
    "\n",
    "# Tell the compiler where to find the Python and pybind11 headers\n",
    "python_include = sysconfig.get_paths()['include']\n",
    "pybind11_include = pybind11.get_include()\n",
    "os.environ['CXXFLAGS'] = f\"-I{python_include} -I{pybind11_include}\"\n",
    "\n",
    "# Optional: help downstream tools pick the right interpreter\n",
    "os.environ['PYTHON_EXECUTABLE'] = sys.executable\n",
    "\n",
    "# Now Vitis\n",
    "os.environ[\"XILINX_VITIS\"] = \"/opt/tools/Xilinx/Vitis/2023.2/\"\n",
    "os.environ[\"XILINX_XRT\"] = \"/opt/xilinx/xrt/\"\n",
    "os.environ[\"XILINX_PLATFORM\"] = \"/opt/xilinx/platforms/xilinx_u55c_gen3x16_xdma_3_202210_1/xilinx_u55c_gen3x16_xdma_3_202210_1.xpfm\"\n",
    "\n",
    "os.environ[\"PATH\"] = (\n",
    "    f\"{os.environ['XILINX_VITIS']}/bin:\"\n",
    "    f\"{os.environ['XILINX_XRT']}/bin:\"\n",
    "    + os.environ[\"PATH\"]\n",
    ")\n",
    "\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = (\n",
    "    f\"{os.environ['XILINX_VITIS']}/lib/lnx64.o:\"\n",
    "    f\"{os.environ['XILINX_XRT']}/lib:\"\n",
    "    + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    ")\n",
    "\n",
    "# General Imports\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import conifer\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# enable more output from conifer\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.WARNING)\n",
    "logger = logging.getLogger('conifer')\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "seed = int('fpga_tutorial'.encode('utf-8').hex(), 16) % 2**31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb870a9d-218b-487f-870d-d61b45d00eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2f43c0-16b9-44c0-8872-928cb98bb596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (Batch  (None, 10)                40        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                220       \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 20)                80        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 10)                40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 10)                40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 751 (2.93 KB)\n",
      "Trainable params: 651 (2.54 KB)\n",
      "Non-trainable params: 100 (400.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create new model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(X.shape[1],)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Dense(20, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "\n",
    "    keras.layers.Dense(10, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "\n",
    "    keras.layers.Dense(10, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b701c858-91bd-44b4-a2db-6f5195e24eda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.08150, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.08150, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 1: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 1: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fpga-env/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 2: val_loss improved from 1.08150 to 0.86437, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 1.08150 to 0.86437, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 2: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 2: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 3: val_loss improved from 0.86437 to 0.79199, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.86437 to 0.79199, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 3: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 3: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 4: val_loss improved from 0.79199 to 0.76794, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.79199 to 0.76794, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 4: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 4: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 5: val_loss improved from 0.76794 to 0.75285, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.76794 to 0.75285, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 5: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 5: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 6: val_loss improved from 0.75285 to 0.73824, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.75285 to 0.73824, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 6: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 6: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 7: val_loss improved from 0.73824 to 0.72093, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.73824 to 0.72093, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 7: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 7: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 8: val_loss improved from 0.72093 to 0.70248, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.72093 to 0.70248, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 8: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 8: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 9: val_loss improved from 0.70248 to 0.68382, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.70248 to 0.68382, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 9: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 9: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 10: val_loss improved from 0.68382 to 0.66699, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.68382 to 0.66699, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 10: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 10: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 10: saving model to model_3/KERAS_check_model_epoch10.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 11: val_loss improved from 0.66699 to 0.65197, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 11: val_loss improved from 0.66699 to 0.65197, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 11: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 11: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 12: val_loss improved from 0.65197 to 0.63923, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 12: val_loss improved from 0.65197 to 0.63923, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 12: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 12: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 13: val_loss improved from 0.63923 to 0.62696, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.63923 to 0.62696, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 13: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 13: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 14: val_loss improved from 0.62696 to 0.61661, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.62696 to 0.61661, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 14: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 14: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 15: val_loss improved from 0.61661 to 0.60698, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.61661 to 0.60698, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 15: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 15: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 16: val_loss improved from 0.60698 to 0.59894, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.60698 to 0.59894, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 16: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 16: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 17: val_loss improved from 0.59894 to 0.59055, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.59894 to 0.59055, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 17: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 17: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 18: val_loss improved from 0.59055 to 0.58303, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.59055 to 0.58303, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 18: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 18: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 19: val_loss improved from 0.58303 to 0.57585, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.58303 to 0.57585, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 19: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 19: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 20: val_loss improved from 0.57585 to 0.56910, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 20: val_loss improved from 0.57585 to 0.56910, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 20: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 20: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 20: saving model to model_3/KERAS_check_model_epoch20.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 21: val_loss improved from 0.56910 to 0.56298, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 21: val_loss improved from 0.56910 to 0.56298, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 21: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 21: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 22: val_loss improved from 0.56298 to 0.55664, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 22: val_loss improved from 0.56298 to 0.55664, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 22: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 22: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 23: val_loss improved from 0.55664 to 0.55085, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.55664 to 0.55085, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 23: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 23: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 24: val_loss improved from 0.55085 to 0.54460, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.55085 to 0.54460, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 24: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 24: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 25: val_loss improved from 0.54460 to 0.53862, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.54460 to 0.53862, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 25: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 25: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 26: val_loss improved from 0.53862 to 0.53296, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.53862 to 0.53296, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 26: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 26: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 27: val_loss improved from 0.53296 to 0.52799, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 27: val_loss improved from 0.53296 to 0.52799, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 27: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 27: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 28: val_loss improved from 0.52799 to 0.52256, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 28: val_loss improved from 0.52799 to 0.52256, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 28: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 28: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 29: val_loss improved from 0.52256 to 0.51706, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 29: val_loss improved from 0.52256 to 0.51706, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 29: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 29: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 30: val_loss improved from 0.51706 to 0.51163, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 30: val_loss improved from 0.51706 to 0.51163, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 30: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 30: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 30: saving model to model_3/KERAS_check_model_epoch30.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 31: val_loss improved from 0.51163 to 0.50626, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 31: val_loss improved from 0.51163 to 0.50626, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 31: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 31: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "\n",
      "***callbacks***\n",
      "saving losses to model_3/losses.log\n",
      "\n",
      "Epoch 32: val_loss improved from 0.50626 to 0.50106, saving model to model_3/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 32: val_loss improved from 0.50626 to 0.50106, saving model to model_3/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 32: saving model to model_3/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 32: saving model to model_3/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "train = True\n",
    "if train:\n",
    "    adam = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=adam, loss=['binary_crossentropy'], metrics=['accuracy'])\n",
    "    callbacks = all_callbacks(\n",
    "        stop_patience=1000,\n",
    "        lr_factor=0.5,\n",
    "        lr_patience=10,\n",
    "        lr_epsilon=0.000001,\n",
    "        lr_cooldown=2,\n",
    "        lr_minimum=0.0000001,\n",
    "        outputDir='model_3',\n",
    "    )\n",
    "    model.fit(\n",
    "        X,\n",
    "        Y,\n",
    "        batch_size=1024,\n",
    "        epochs=32,\n",
    "        validation_split=0.25,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks.callbacks,\n",
    "        verbose = 0\n",
    "    )\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "\n",
    "    model = load_model('model_2/KERAS_check_best_model.h5')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ee4729-c899-43ed-ad6a-37f3e8d6b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601/601 [==============================] - 1s 889us/step\n",
      "0.9114745397418857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3cb0795150>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "tpr, fpr, _ = metrics.roc_curve(Y_test, Y_pred)\n",
    "performance = metrics.auc(tpr, fpr)\n",
    "print(performance)\n",
    "plt.plot(tpr, fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1800b7-0074-4edf-879a-981f066c823b",
   "metadata": {},
   "source": [
    "HLS4ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21ec92c4-169d-4b86-ba11-8f8bd5868812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Layer name: batch_normalization, layer type: BatchNormalization, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 10]], output shape: [None, 20]\n",
      "Layer name: batch_normalization_1, layer type: BatchNormalization, input shapes: [[None, 20]], output shape: [None, 20]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 20]], output shape: [None, 10]\n",
      "Layer name: batch_normalization_2, layer type: BatchNormalization, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Layer name: batch_normalization_3, layer type: BatchNormalization, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 10]], output shape: [None, 1]\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Layer name: batch_normalization, layer type: BatchNormalization, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 10]], output shape: [None, 20]\n",
      "Layer name: batch_normalization_1, layer type: BatchNormalization, input shapes: [[None, 20]], output shape: [None, 20]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 20]], output shape: [None, 10]\n",
      "Layer name: batch_normalization_2, layer type: BatchNormalization, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Layer name: batch_normalization_3, layer type: BatchNormalization, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 10]], output shape: [None, 1]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "print(\"-----------------------------------\")\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, hls_config=config, output_dir='model_2/hls4ml_prj_pynq', backend='Vitis', board='pynq-z2'\n",
    ")\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ff4ba7-2bbb-4ed7-a717-f588835c39c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2023.2 (64-bit)\n",
      "  **** SW Build 4023990 on Oct 11 2023\n",
      "  **** IP Build 4028589 on Sat Oct 14 00:45:43 MDT 2023\n",
      "  **** SharedData Build 4025554 on Tue Oct 10 17:18:54 MDT 2023\n",
      "    ** Copyright 1986-2022 Xilinx, Inc. All Rights Reserved.\n",
      "    ** Copyright 2022-2023 Advanced Micro Devices, Inc. All Rights Reserved.\n",
      "\n",
      "source /opt/tools/Xilinx/Vitis_HLS/2023.2/scripts/vitis_hls/hls.tcl -notrace\n",
      "INFO: [HLS 200-10] Running '/opt/tools/Xilinx/Vitis_HLS/2023.2/bin/unwrapped/lnx64.o/vitis_hls'\n",
      "INFO: [HLS 200-10] For user 'bspanu' on host 'c33aa6035e82' (Linux_x86_64 version 5.4.0-169-generic) on Fri Sep 05 09:26:40 UTC 2025\n",
      "INFO: [HLS 200-10] On os Ubuntu 24.04.2 LTS\n",
      "INFO: [HLS 200-10] In directory '/home/bspanu/hackathon/model_2/hls4ml_prj_pynq'\n",
      "INFO: [HLS 200-2053] The vitis_hls executable is being deprecated. Consider using vitis-run --mode hls --tcl\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-1510] Running: open_project -reset myproject_prj \n",
      "INFO: [HLS 200-10] Creating and opening project '/home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj'.\n",
      "INFO: [HLS 200-1510] Running: set_top myproject \n",
      "INFO: [HLS 200-1510] Running: add_files firmware/myproject.cpp -cflags -std=c++0x \n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject.cpp' to the project\n",
      "INFO: [HLS 200-1510] Running: add_files -tb myproject_test.cpp -cflags -std=c++0x \n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [HLS 200-1510] Running: add_files -tb firmware/weights \n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-1510] Running: add_files -tb tb_data \n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-1510] Running: open_solution -reset solution1 \n",
      "INFO: [HLS 200-10] Creating and opening solution '/home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1'.\n",
      "INFO: [HLS 200-10] Cleaning up the solution database.\n",
      "INFO: [HLS 200-1505] Using default flow_target 'vivado'\n",
      "Resolution: For help on HLS 200-1505 see docs.xilinx.com/access/sources/dita/topic?Doc_Version=2023.2%20English&url=ug1448-hls-guidance&resourceid=200-1505.html\n",
      "INFO: [HLS 200-1510] Running: config_array_partition -maximum_size 4096 \n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "ERROR: [HLS 200-642] The 'config_array_partition -maximum_size' command is not supported.\n",
      "INFO: [HLS 200-1510] Running: config_compile -name_max_length 80 \n",
      "INFO: [XFORM 203-1161] The maximum of name length is set to 80.\n",
      "INFO: [HLS 200-1510] Running: set_part xcvu13p-flga2577-2-e \n",
      "INFO: [HLS 200-1611] Setting target device to 'xcvu13p-flga2577-2-e'\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set to 80.\n",
      "INFO: [HLS 200-1510] Running: config_schedule -enable_dsp_full_reg=false \n",
      "INFO: [HLS 200-1510] Running: create_clock -period 5 -name default \n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.\n",
      "INFO: [HLS 200-1510] Running: set_clock_uncertainty 27% default \n",
      "INFO: [SYN 201-201] Setting up clock 'default' with an uncertainty of 1.35ns.\n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [HLS 200-1510] Running: csynth_design \n",
      "INFO: [HLS 200-111] Finished File checks and directory preparation: CPU user time: 0.06 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.07 seconds; current allocated memory: 257.023 MB.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... \n",
      "WARNING: [HLS 207-5536] 'Resource pragma' is deprecated, use 'bind_op/bind_storage pragma' instead (firmware/nnet_utils/nnet_dense_resource.h:33:9)\n",
      "WARNING: [HLS 207-5536] 'Resource pragma' is deprecated, use 'bind_op/bind_storage pragma' instead (firmware/nnet_utils/nnet_dense_resource.h:107:9)\n",
      "WARNING: [HLS 207-5536] 'Resource pragma' is deprecated, use 'bind_op/bind_storage pragma' instead (firmware/nnet_utils/nnet_dense_resource.h:189:9)\n",
      "WARNING: [HLS 207-5292] unused parameter 'keep' (firmware/nnet_utils/nnet_helpers.h:285:99)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:14:36)\n",
      "WARNING: [HLS 207-5292] unused parameter 'buffer' (firmware/nnet_utils/nnet_function_stubs.h:15:36)\n",
      "WARNING: [HLS 207-5292] unused parameter 'partition' (firmware/nnet_utils/nnet_function_stubs.h:16:44)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:24:24)\n",
      "WARNING: [HLS 207-5292] unused parameter 'buffer' (firmware/nnet_utils/nnet_function_stubs.h:25:24)\n",
      "WARNING: [HLS 207-5292] unused parameter 'partition' (firmware/nnet_utils/nnet_function_stubs.h:26:32)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:33:30)\n",
      "WARNING: [HLS 207-5292] unused parameter 'res' (firmware/nnet_utils/nnet_function_stubs.h:33:58)\n",
      "WARNING: [HLS 207-5292] unused parameter 'weights' (firmware/nnet_utils/nnet_function_stubs.h:34:51)\n",
      "WARNING: [HLS 207-5292] unused parameter 'biases' (firmware/nnet_utils/nnet_function_stubs.h:35:49)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:42:30)\n",
      "WARNING: [HLS 207-5292] unused parameter 'res' (firmware/nnet_utils/nnet_function_stubs.h:42:58)\n",
      "WARNING: [HLS 207-5292] unused parameter 'weights' (firmware/nnet_utils/nnet_function_stubs.h:43:51)\n",
      "WARNING: [HLS 207-5292] unused parameter 'biases' (firmware/nnet_utils/nnet_function_stubs.h:44:49)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:51:29)\n",
      "WARNING: [HLS 207-5292] unused parameter 'res' (firmware/nnet_utils/nnet_function_stubs.h:51:80)\n",
      "WARNING: [HLS 207-5292] unused parameter 'weights' (firmware/nnet_utils/nnet_function_stubs.h:52:50)\n",
      "WARNING: [HLS 207-5292] unused parameter 'biases' (firmware/nnet_utils/nnet_function_stubs.h:53:48)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_code_gen.h:16:39)\n",
      "WARNING: [HLS 207-5292] unused parameter 'res' (firmware/nnet_utils/nnet_code_gen.h:17:38)\n",
      "WARNING: [HLS 207-5292] unused parameter 'weights' (firmware/nnet_utils/nnet_code_gen.h:18:60)\n",
      "WARNING: [HLS 207-5292] unused parameter 'biases' (firmware/nnet_utils/nnet_code_gen.h:19:58)\n",
      "INFO: [HLS 200-111] Finished Source Code Analysis and Preprocessing: CPU user time: 7.79 seconds. CPU system time: 1.19 seconds. Elapsed time: 9.41 seconds; current allocated memory: 263.875 MB.\n",
      "INFO: [HLS 200-777] Using interface defaults for 'Vivado' flow target.\n",
      "INFO: [HLS 200-1995] There were 5,578 instructions in the design after the 'Compile/Link' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 35,493 instructions in the design after the 'Unroll/Inline (step 1)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 10,307 instructions in the design after the 'Unroll/Inline (step 2)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 10,431 instructions in the design after the 'Unroll/Inline (step 3)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 9,849 instructions in the design after the 'Unroll/Inline (step 4)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 6,891 instructions in the design after the 'Array/Struct (step 1)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 6,074 instructions in the design after the 'Array/Struct (step 2)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 6,074 instructions in the design after the 'Array/Struct (step 3)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 6,090 instructions in the design after the 'Array/Struct (step 4)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 6,066 instructions in the design after the 'Array/Struct (step 5)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 6,066 instructions in the design after the 'Performance (step 1)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 6,066 instructions in the design after the 'Performance (step 2)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 6,066 instructions in the design after the 'Performance (step 3)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 6,066 instructions in the design after the 'Performance (step 4)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 6,068 instructions in the design after the 'HW Transforms (step 1)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 200-1995] There were 6,082 instructions in the design after the 'HW Transforms (step 2)' phase of compilation. See the Design Size Report for more details: /home/bspanu/hackathon/model_2/hls4ml_prj_pynq/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, config2::scale_t*, config2::bias_t*)' (firmware/nnet_utils/nnet_batchnorm.h:54:25)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, config3::weight_t*, config3::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:42:27)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::DenseLatency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>::dense(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' into 'void nnet::dense<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, config3::weight_t*, config3::bias_t*)' (firmware/nnet_utils/nnet_dense.h:45:2)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, config5::scale_t*, config5::bias_t*)' (firmware/nnet_utils/nnet_batchnorm.h:54:25)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>*, config6::weight_t*, config6::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:42:27)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::DenseLatency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>::dense(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' into 'void nnet::dense<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>*, config6::weight_t*, config6::bias_t*)' (firmware/nnet_utils/nnet_dense.h:45:2)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, config8::scale_t*, config8::bias_t*)' (firmware/nnet_utils/nnet_batchnorm.h:54:25)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, config9::weight_t*, config9::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:42:27)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::DenseLatency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>::dense(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' into 'void nnet::dense<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, config9::weight_t*, config9::bias_t*)' (firmware/nnet_utils/nnet_dense.h:45:2)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, config11::scale_t*, config11::bias_t*)' (firmware/nnet_utils/nnet_batchnorm.h:54:25)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, config12::weight_t*, config12::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:42:27)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::DenseLatency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>::dense(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' into 'void nnet::dense<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, config12::weight_t*, config12::bias_t*)' (firmware/nnet_utils/nnet_dense.h:45:2)\n",
      "INFO: [HLS 214-131] Inlining function 'void nnet::dense<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, config3::weight_t*, config3::bias_t*)' into 'myproject(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (firmware/myproject.cpp:52:2)\n",
      "INFO: [HLS 214-131] Inlining function 'void nnet::dense<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>*, config6::weight_t*, config6::bias_t*)' into 'myproject(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (firmware/myproject.cpp:64:2)\n",
      "INFO: [HLS 214-131] Inlining function 'void nnet::dense<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, config9::weight_t*, config9::bias_t*)' into 'myproject(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (firmware/myproject.cpp:76:2)\n",
      "INFO: [HLS 214-131] Inlining function 'void nnet::dense<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, config12::weight_t*, config12::bias_t*)' into 'myproject(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (firmware/myproject.cpp:88:2)\n",
      "INFO: [HLS 214-291] Loop 'VITIS_LOOP_114_1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_activation.h:114:23)\n",
      "INFO: [HLS 214-291] Loop 'Result' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:64:5)\n",
      "INFO: [HLS 214-291] Loop 'Accum1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:54:5)\n",
      "INFO: [HLS 214-291] Loop 'Accum2' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:56:9)\n",
      "INFO: [HLS 214-291] Loop 'ResetAccum' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:48:5)\n",
      "INFO: [HLS 214-291] Loop 'Product1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:37:5)\n",
      "INFO: [HLS 214-291] Loop 'Product2' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:40:9)\n",
      "INFO: [HLS 214-291] Loop 'Result' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_batchnorm.h:52:5)\n",
      "INFO: [HLS 214-291] Loop 'VITIS_LOOP_43_1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_activation.h:43:22)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_114_1' (firmware/nnet_utils/nnet_activation.h:114:23) in function 'nnet::sigmoid<ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, sigmoid_config13>' completely with a factor of 1 (firmware/nnet_utils/nnet_activation.h:95:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:64:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' completely with a factor of 1 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:54:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:56:9) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' completely with a factor of 1 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:48:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' completely with a factor of 1 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:40:9) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' completely with a factor of 1 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_batchnorm.h:52:5) in function 'nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 10 (firmware/nnet_utils/nnet_batchnorm.h:33:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_43_1' (firmware/nnet_utils/nnet_activation.h:43:22) in function 'nnet::relu<ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, relu_config10>' completely with a factor of 10 (firmware/nnet_utils/nnet_activation.h:39:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:64:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:54:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:56:9) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:48:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:40:9) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_batchnorm.h:52:5) in function 'nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' completely with a factor of 10 (firmware/nnet_utils/nnet_batchnorm.h:33:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_43_1' (firmware/nnet_utils/nnet_activation.h:43:22) in function 'nnet::relu<ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, relu_config7>' completely with a factor of 10 (firmware/nnet_utils/nnet_activation.h:39:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:64:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:54:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 20 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:56:9) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:48:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 20 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:40:9) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_batchnorm.h:52:5) in function 'nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 20 (firmware/nnet_utils/nnet_batchnorm.h:33:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_43_1' (firmware/nnet_utils/nnet_activation.h:43:22) in function 'nnet::relu<ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, relu_config4>' completely with a factor of 20 (firmware/nnet_utils/nnet_activation.h:39:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:64:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 20 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:54:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:56:9) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 20 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:48:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 20 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37:5) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 10 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:40:9) in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 20 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_batchnorm.h:52:5) in function 'nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 10 (firmware/nnet_utils/nnet_batchnorm.h:33:0)\n",
      "INFO: [HLS 214-178] Inlining function 'std::enable_if<!(std::is_same<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_uint<1> >::value), ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0> >::type nnet::cast<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>(config3::accum_t)' into 'void nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, config3::weight_t*, config3::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-178] Inlining function 'std::enable_if<!(std::is_same<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_uint<1> >::value), ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0> >::type nnet::cast<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>(config6::accum_t)' into 'void nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>*, config6::weight_t*, config6::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-178] Inlining function 'std::enable_if<!(std::is_same<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_uint<1> >::value), ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0> >::type nnet::cast<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>(config9::accum_t)' into 'void nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, config9::weight_t*, config9::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-178] Inlining function 'std::enable_if<!(std::is_same<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_uint<1> >::value), ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0> >::type nnet::cast<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>(config12::accum_t)' into 'void nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>(ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>*, config12::weight_t*, config12::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b12': Complete partitioning on dimension 1. (firmware/weights/b12.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b11': Complete partitioning on dimension 1. (firmware/weights/b11.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 's11': Complete partitioning on dimension 1. (firmware/weights/s11.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b9': Complete partitioning on dimension 1. (firmware/weights/b9.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b8': Complete partitioning on dimension 1. (firmware/weights/b8.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 's8': Complete partitioning on dimension 1. (firmware/weights/s8.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b6': Complete partitioning on dimension 1. (firmware/weights/b6.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b5': Complete partitioning on dimension 1. (firmware/weights/b5.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 's5': Complete partitioning on dimension 1. (firmware/weights/s5.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b3': Complete partitioning on dimension 1. (firmware/weights/b3.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b2': Complete partitioning on dimension 1. (firmware/weights/b2.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 's2': Complete partitioning on dimension 1. (firmware/weights/s2.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'mult': Complete partitioning on dimension 1. (firmware/nnet_utils/nnet_dense_latency.h:17:32)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer2_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:46:31)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer3_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:50:20)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer4_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:54:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer5_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:58:36)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer6_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:62:22)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer7_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:66:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer8_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:70:36)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer9_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:74:22)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer10_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:78:15)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer11_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:82:36)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer12_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:86:22)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer13_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:10:0)\n",
      "INFO: [HLS 214-248] Applying array_reshape to 'input_1': Complete reshaping on dimension 1. (firmware/myproject.cpp:10:0)\n",
      "INFO: [HLS 200-111] Finished Compiling Optimization and Transform: CPU user time: 6.13 seconds. CPU system time: 1.04 seconds. Elapsed time: 9.33 seconds; current allocated memory: 266.816 MB.\n",
      "INFO: [HLS 200-111] Finished Checking Pragmas: CPU user time: 0 seconds. CPU system time: 0 seconds. Elapsed time: 0 seconds; current allocated memory: 266.816 MB.\n",
      "INFO: [HLS 200-10] Starting code transformations ...\n",
      "INFO: [HLS 200-111] Finished Standard Transforms: CPU user time: 0.12 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.18 seconds; current allocated memory: 272.391 MB.\n",
      "INFO: [HLS 200-10] Checking synthesizability ...\n",
      "INFO: [HLS 200-111] Finished Checking Synthesizability: CPU user time: 0.14 seconds. CPU system time: 0 seconds. Elapsed time: 0.13 seconds; current allocated memory: 276.602 MB.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation.h:115:31) to (firmware/nnet_utils/nnet_activation.h:123:1) in function 'nnet::sigmoid<ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, sigmoid_config13>'... converting 3 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation.h:42:9) to (firmware/nnet_utils/nnet_activation.h:50:1) in function 'nnet::relu<ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, relu_config7>'... converting 21 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation.h:42:9) to (firmware/nnet_utils/nnet_activation.h:50:1) in function 'nnet::relu<ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, relu_config4>'... converting 41 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation.h:42:9) to (firmware/nnet_utils/nnet_activation.h:50:1) in function 'nnet::relu<ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, relu_config10>'... converting 21 basic blocks.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<55, 25, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' (firmware/nnet_utils/nnet_mult.h:33:11)...200 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' (firmware/nnet_utils/nnet_mult.h:33:12)...100 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' (firmware/nnet_utils/nnet_dense_latency.h:33:21)...160 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_latency<ap_fixed<33, 13, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<54, 24, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' (firmware/nnet_utils/nnet_dense_latency.h:33:1)...10 expression(s) balanced.\n",
      "INFO: [HLS 200-111] Finished Loop, function and other optimizations: CPU user time: 0.41 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.46 seconds; current allocated memory: 308.684 MB.\n",
      "INFO: [HLS 200-111] Finished Architecture Synthesis: CPU user time: 0.35 seconds. CPU system time: 0.04 seconds. Elapsed time: 0.42 seconds; current allocated memory: 427.445 MB.\n",
      "INFO: [HLS 200-10] Starting hardware synthesis ...\n",
      "INFO: [HLS 200-10] Synthesizing 'myproject' ...\n",
      "WARNING: [SYN 201-103] Legalizing function name 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>' to 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_latency<ap_fixed<33, 13, 5, 3, 0>, ap_fixed<54, 24, 5, 3, 0>, config3>' to 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_54_24_5_3_0_config3_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<ap_fixed<54, 24, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config4>' to 'relu_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_relu_config4_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config5>' to 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config5_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_latency<ap_fixed<33, 13, 5, 3, 0>, ap_fixed<55, 25, 5, 3, 0>, config6>' to 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_55_25_5_3_0_config6_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<ap_fixed<55, 25, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config7>' to 'relu_ap_fixed_55_25_5_3_0_ap_fixed_16_6_5_3_0_relu_config7_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config8>' to 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config8_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_latency<ap_fixed<33, 13, 5, 3, 0>, ap_fixed<54, 24, 5, 3, 0>, config9>' to 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_54_24_5_3_0_config9_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<ap_fixed<54, 24, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config10>' to 'relu_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_relu_config10_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config11>' to 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config11_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_latency<ap_fixed<33, 13, 5, 3, 0>, ap_fixed<54, 24, 5, 3, 0>, config12>' to 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_54_24_5_3_0_config12_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'sigmoid<ap_fixed<54, 24, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, sigmoid_config13>' to 'sigmoid_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_sigmoid_config13_s'.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config2>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.13 seconds. CPU system time: 0.03 seconds. Elapsed time: 0.19 seconds; current allocated memory: 428.449 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.03 seconds. CPU system time: 0 seconds. Elapsed time: 0.03 seconds; current allocated memory: 428.582 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_54_24_5_3_0_config3_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'dense_latency<ap_fixed<33, 13, 5, 3, 0>, ap_fixed<54, 24, 5, 3, 0>, config3>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 2, function 'dense_latency<ap_fixed<33, 13, 5, 3, 0>, ap_fixed<54, 24, 5, 3, 0>, config3>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 1.11 seconds. CPU system time: 0 seconds. Elapsed time: 1.1 seconds; current allocated memory: 433.723 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.24 seconds. CPU system time: 0 seconds. Elapsed time: 0.24 seconds; current allocated memory: 442.746 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_relu_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'relu<ap_fixed<54, 24, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config4>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'relu<ap_fixed<54, 24, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config4>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.12 seconds. CPU system time: 0.02 seconds. Elapsed time: 0.13 seconds; current allocated memory: 442.746 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.04 seconds. CPU system time: 0 seconds. Elapsed time: 0.04 seconds; current allocated memory: 442.746 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config5>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config5>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.17 seconds. CPU system time: 0 seconds. Elapsed time: 0.17 seconds; current allocated memory: 442.746 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.04 seconds. CPU system time: 0 seconds. Elapsed time: 0.04 seconds; current allocated memory: 442.746 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_55_25_5_3_0_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'dense_latency<ap_fixed<33, 13, 5, 3, 0>, ap_fixed<55, 25, 5, 3, 0>, config6>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 2, function 'dense_latency<ap_fixed<33, 13, 5, 3, 0>, ap_fixed<55, 25, 5, 3, 0>, config6>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 1.37 seconds. CPU system time: 0 seconds. Elapsed time: 1.51 seconds; current allocated memory: 442.992 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.31 seconds. CPU system time: 0.02 seconds. Elapsed time: 0.32 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_ap_fixed_55_25_5_3_0_ap_fixed_16_6_5_3_0_relu_config7_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'relu<ap_fixed<55, 25, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config7>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'relu<ap_fixed<55, 25, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config7>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.11 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.13 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.03 seconds. CPU system time: 0 seconds. Elapsed time: 0.03 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config8>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config8>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.09 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.1 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.04 seconds. CPU system time: 0 seconds. Elapsed time: 0.04 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_54_24_5_3_0_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'dense_latency<ap_fixed<33, 13, 5, 3, 0>, ap_fixed<54, 24, 5, 3, 0>, config9>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 2, function 'dense_latency<ap_fixed<33, 13, 5, 3, 0>, ap_fixed<54, 24, 5, 3, 0>, config9>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.71 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.72 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.12 seconds. CPU system time: 0 seconds. Elapsed time: 0.13 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_relu_config10_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'relu<ap_fixed<54, 24, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config10>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'relu<ap_fixed<54, 24, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config10>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.08 seconds. CPU system time: 0 seconds. Elapsed time: 0.09 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.04 seconds. CPU system time: 0 seconds. Elapsed time: 0.04 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config11>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<33, 13, 5, 3, 0>, config11>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.1 seconds. CPU system time: 0 seconds. Elapsed time: 0.1 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.04 seconds. CPU system time: 0 seconds. Elapsed time: 0.04 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_54_24_5_3_0_config12_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'dense_latency<ap_fixed<33, 13, 5, 3, 0>, ap_fixed<54, 24, 5, 3, 0>, config12>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 2, function 'dense_latency<ap_fixed<33, 13, 5, 3, 0>, ap_fixed<54, 24, 5, 3, 0>, config12>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.1 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.11 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.04 seconds. CPU system time: 0 seconds. Elapsed time: 0.04 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'sigmoid_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_sigmoid_config13_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'sigmoid<ap_fixed<54, 24, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, sigmoid_config13>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 3, function 'sigmoid<ap_fixed<54, 24, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, sigmoid_config13>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.07 seconds. CPU system time: 0 seconds. Elapsed time: 0.07 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.03 seconds. CPU system time: 0 seconds. Elapsed time: 0.04 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'myproject' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'myproject'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 16, function 'myproject'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.11 seconds. CPU system time: 0 seconds. Elapsed time: 0.1 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.06 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.06 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_11ns_26_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_12ns_27_1_1': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_8ns_23_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_8ns_24_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_9ns_24_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config2_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.09 seconds. CPU system time: 0 seconds. Elapsed time: 0.12 seconds; current allocated memory: 455.344 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_54_24_5_3_0_config3_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-104] Estimated max fanout for 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_54_24_5_3_0_config3_s' is 6926 from HDL expression: (1'b0 == ap_block_pp0_stage0)\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_10ns_36_1_0': 38 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_10s_36_1_0': 32 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_6ns_36_1_0': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_6s_36_1_0': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_7ns_36_1_0': 4 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_7s_36_1_0': 4 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_8ns_36_1_0': 10 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_8s_36_1_0': 12 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_9ns_36_1_0': 17 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_9s_36_1_0': 17 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_54_24_5_3_0_config3_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.2 seconds. CPU system time: 0.03 seconds. Elapsed time: 0.26 seconds; current allocated memory: 462.551 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'relu_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_relu_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'relu_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_relu_config4_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.28 seconds. CPU system time: 0.02 seconds. Elapsed time: 0.3 seconds; current allocated memory: 475.824 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_12ns_27_1_1': 11 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_13ns_28_1_1': 9 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config5_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.11 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.12 seconds; current allocated memory: 478.062 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_55_25_5_3_0_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-104] Estimated max fanout for 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_55_25_5_3_0_config6_s' is 8877 from HDL expression: (1'b0 == ap_block_pp0_stage0)\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_10ns_36_1_0': 31 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_10s_36_1_0': 46 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_5s_36_1_0': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_6ns_36_1_0': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_6s_36_1_0': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_7ns_36_1_0': 9 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_7s_36_1_0': 5 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_8ns_36_1_0': 13 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_8s_36_1_0': 7 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_9ns_36_1_0': 33 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_9s_36_1_0': 30 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_55_25_5_3_0_config6_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.23 seconds. CPU system time: 0.02 seconds. Elapsed time: 0.26 seconds; current allocated memory: 486.922 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'relu_ap_fixed_55_25_5_3_0_ap_fixed_16_6_5_3_0_relu_config7_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'relu_ap_fixed_55_25_5_3_0_ap_fixed_16_6_5_3_0_relu_config7_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.33 seconds. CPU system time: 0.02 seconds. Elapsed time: 0.36 seconds; current allocated memory: 502.879 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_11ns_26_1_1': 3 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_12ns_27_1_1': 7 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config8_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.08 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.1 seconds; current allocated memory: 503.309 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_54_24_5_3_0_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_10ns_36_1_0': 15 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_10s_36_1_0': 22 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_11ns_36_1_0': 5 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_11s_36_1_0': 4 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_6s_36_1_0': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_7ns_36_1_0': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_8ns_36_1_0': 7 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_8s_36_1_0': 7 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_9ns_36_1_0': 12 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_9s_36_1_0': 17 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_54_24_5_3_0_config9_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.15 seconds. CPU system time: 0.02 seconds. Elapsed time: 0.2 seconds; current allocated memory: 507.160 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'relu_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_relu_config10_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'relu_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_relu_config10_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.17 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.19 seconds; current allocated memory: 514.777 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_11ns_26_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_12ns_27_1_1': 9 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_33_13_5_3_0_config11_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.07 seconds. CPU system time: 0.02 seconds. Elapsed time: 0.08 seconds; current allocated memory: 518.492 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_54_24_5_3_0_config12_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_10ns_36_1_0': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_10s_36_1_0': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_11ns_36_1_0': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_11s_36_1_0': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_8ns_36_1_0': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_9ns_36_1_0': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_33s_9s_36_1_0': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_latency_ap_fixed_33_13_5_3_0_ap_fixed_54_24_5_3_0_config12_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.09 seconds. CPU system time: 0 seconds. Elapsed time: 0.09 seconds; current allocated memory: 520.293 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'sigmoid_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_sigmoid_config13_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'sigmoid_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_sigmoid_config13_s_sigmoid_table_ROM_AUTO_1R' to 'sigmoid_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_sigmoid_config13_s_sigmoid_tbkb' due to the length limit 80\n",
      "INFO: [HLS 200-1030] Apply Unified Pipeline Control on module 'sigmoid_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_sigmoid_config13_s' pipeline 'sigmoid<ap_fixed<54, 24, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, sigmoid_config13>' pipeline type 'function pipeline'\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'sigmoid_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_sigmoid_config13_s'.\n",
      "INFO: [RTMG 210-279] Implementing memory 'myproject_sigmoid_ap_fixed_54_24_5_3_0_ap_fixed_16_6_5_3_0_sigmoid_config13_s_sigmoid_tbkb' using auto ROMs.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.08 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.1 seconds; current allocated memory: 522.238 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'myproject' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/input_1' to 'ap_vld'.\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject/layer13_out' to 'ap_vld'.\n",
      "INFO: [RTGEN 206-500] Setting interface mode on function 'myproject' to 'ap_ctrl_hs'.\n",
      "INFO: [HLS 200-1030] Apply Unified Pipeline Control on module 'myproject' pipeline 'myproject' pipeline type 'function pipeline'\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'myproject'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.12 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.13 seconds; current allocated memory: 524.426 MB.\n",
      "INFO: [HLS 200-111] Finished Generating all RTL models: CPU user time: 0.3 seconds. CPU system time: 0.03 seconds. Elapsed time: 0.39 seconds; current allocated memory: 529.023 MB.\n",
      "INFO: [HLS 200-111] Finished Updating report files: CPU user time: 0.56 seconds. CPU system time: 0.03 seconds. Elapsed time: 0.61 seconds; current allocated memory: 544.703 MB.\n",
      "INFO: [VHDL 208-304] Generating VHDL RTL for myproject.\n",
      "INFO: [VLOG 209-307] Generating Verilog RTL for myproject.\n",
      "INFO: [HLS 200-789] **** Estimated Fmax: 294.96 MHz\n",
      "INFO: [HLS 200-111] Finished Command csynth_design CPU user time: 23.28 seconds. CPU system time: 2.69 seconds. Elapsed time: 29.07 seconds; current allocated memory: 288.207 MB.\n",
      "***** C/RTL SYNTHESIS COMPLETED IN 0h0m29s *****\n",
      "***** VIVADO SYNTHESIS *****\n",
      "\n",
      "****** Vivado v2023.2 (64-bit)\n",
      "  **** SW Build 4029153 on Fri Oct 13 20:13:54 MDT 2023\n",
      "  **** IP Build 4028589 on Sat Oct 14 00:45:43 MDT 2023\n",
      "  **** SharedData Build 4025554 on Tue Oct 10 17:18:54 MDT 2023\n",
      "    ** Copyright 1986-2022 Xilinx, Inc. All Rights Reserved.\n",
      "    ** Copyright 2022-2023 Advanced Micro Devices, Inc. All Rights Reserved.\n",
      "\n",
      "source vivado_synth.tcl\n",
      "# set tcldir [file dirname [info script]]\n",
      "# source [file join $tcldir project.tcl]\n",
      "## variable project_name\n",
      "## set project_name \"myproject\"\n",
      "## variable backend\n",
      "## set backend \"vitis\"\n",
      "## variable part\n",
      "## set part \"xcvu13p-flga2577-2-e\"\n",
      "## variable clock_period\n",
      "## set clock_period 5\n",
      "## variable clock_uncertainty\n",
      "## set clock_uncertainty 27%\n",
      "## variable version\n",
      "## set version \"1.0.0\"\n",
      "## variable maximum_size\n",
      "## set maximum_size 4096\n",
      "# add_files ${project_name}_prj/solution1/syn/verilog\n",
      "add_files: Time (s): cpu = 00:00:06 ; elapsed = 00:00:07 . Memory (MB): peak = 1340.109 ; gain = 44.840 ; free physical = 30237 ; free virtual = 45055\n",
      "# synth_design -top ${project_name} -part $part\n",
      "Command: synth_design -top myproject -part xcvu13p-flga2577-2-e\n",
      "Starting synth_design\n",
      "Attempting to get a license for feature 'Synthesis' and/or device 'xcvu13p'\n",
      "WARNING: [Common 17-348] Failed to get the license for feature 'Synthesis' and/or device 'xcvu13p'. Explanation: The license feature Synthesis could not be found.\n",
      "Resolution: Check the status of your licenses in the Vivado License Manager. For debug help search Xilinx Support for \"Licensing FAQ\". \n",
      "0 Infos, 1 Warnings, 0 Critical Warnings and 1 Errors encountered.\n",
      "synth_design failed\n",
      "INFO: [Common 17-206] Exiting Vivado at Fri Sep  5 09:27:29 2025...\n",
      "ERROR: [Common 17-345] A valid license was not found for feature 'Synthesis' and/or device 'xcvu13p'. Please run the Vivado License Manager for assistance in determining\n",
      "which features and devices are licensed for your system.\n",
      "Resolution: Check the status of your licenses in the Vivado License Manager. For debug help search Xilinx Support for \"Licensing FAQ\". If you are using a license server, verify that the license server is up and running a version of the xilinx daemon that is compatible with the version of Xilinx software that you are using. Note: Vivado 2021.1 and later versions require upgrading your license server tools to the Flex 11.17.2.0 versions. Please confirm with your license admin that the correct version of the license server tools are installed.\n",
      "    while executing\n",
      "\"exec vivado -mode batch -source vivado_synth.tcl >@ stdout\"\n",
      "    invoked from within\n",
      "\"if {$opt(vsynth)} {\n",
      "    puts \"***** VIVADO SYNTHESIS *****\"\n",
      "    if {[file exist ${project_name}_prj/solution1/syn/verilog]} {\n",
      "        set time_start [...\"\n",
      "    (file \"build_prj.tcl\" line 241)\n",
      "    invoked from within\n",
      "\"source build_prj.tcl\"\n",
      "    (\"uplevel\" body line 1)\n",
      "    invoked from within\n",
      "\"uplevel \\#0 [list source $tclfile] \"\n",
      "\n",
      "INFO: [HLS 200-112] Total CPU user time: 37.03 seconds. Total CPU system time: 4.88 seconds. Total elapsed time: 60.05 seconds; peak allocated memory: 545.230 MB.\n",
      "INFO: [Common 17-206] Exiting vitis_hls at Fri Sep  5 09:27:39 2025...\n",
      "Vivado synthesis report not found.\n",
      "Cosim report not found.\n",
      "Timing report not found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CSynthesisReport': {'TargetClockPeriod': '5.00',\n",
       "  'EstimatedClockPeriod': '3.390',\n",
       "  'BestLatency': '15',\n",
       "  'WorstLatency': '15',\n",
       "  'IntervalMin': '1',\n",
       "  'IntervalMax': '1',\n",
       "  'BRAM_18K': '1',\n",
       "  'DSP': '872',\n",
       "  'FF': '11829',\n",
       "  'LUT': '24798',\n",
       "  'URAM': '0',\n",
       "  'AvailableBRAM_18K': '5376',\n",
       "  'AvailableDSP': '12288',\n",
       "  'AvailableFF': '3456000',\n",
       "  'AvailableLUT': '1728000',\n",
       "  'AvailableURAM': '1280'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model.build(csim=False, vsynth=True, synth=True, reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af67cd1-6d92-4b5a-b17d-06b29212b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report('model_1/hls4ml_prj/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6b506-a46e-4720-8443-6c65ac66fb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (fpga-ml)",
   "language": "python",
   "name": "fpga-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
