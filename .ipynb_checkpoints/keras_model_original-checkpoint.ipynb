{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9505b3d-25bf-4be7-ad13-024ad588a469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import conifer ydf converter\n",
      "/opt/conda/envs/fpga-env/lib/python3.10/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'underscore_attrs_are_private' has been removed\n",
      "  warnings.warn(message, UserWarning)\n",
      "/opt/conda/envs/fpga-env/lib/python3.10/site-packages/pynqutils/build_utils/xsa_parser.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/opt/conda/envs/fpga-env/lib/python3.10/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'underscore_attrs_are_private' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# INFN-MIB Cloud Environment Paths\n",
    "import os\n",
    "import sys\n",
    "import sysconfig\n",
    "import pybind11\n",
    "\n",
    "# Add Viavado bin\n",
    "os.environ['PATH'] = '/opt/tools/Xilinx/Vivado/2023.2/bin:' + os.environ['PATH']\n",
    "\n",
    "# Pynq-Z2 files\n",
    "os.environ[\"BOARD_REPO_PATHS\"] = \"/opt/tools/Xilinx/Vivado/2023.2/data/boards/board_files/pynq-z2\"\n",
    "\n",
    "# Add HLS bin\n",
    "os.environ['PATH'] = '/opt/tools/Xilinx/Vitis_HLS/2023.2/bin:' + os.environ['PATH']\n",
    "os.environ['XILINX_HLS'] = '/opt/tools/Xilinx/Vitis_HLS/2023.2/'\n",
    "\n",
    "# Use system compilers\n",
    "os.environ['CC'] = '/usr/bin/gcc'\n",
    "os.environ['CXX'] = '/usr/bin/g++'\n",
    "os.environ['LD'] = '/usr/bin/ld'\n",
    "\n",
    "## Python bindings\n",
    "# Force shell subprocesses to use the right python\n",
    "env_path = os.environ['PATH']\n",
    "correct_python_dir = os.path.dirname(sys.executable)\n",
    "os.environ['PATH'] = f\"{correct_python_dir}:{env_path}\"\n",
    "\n",
    "# Tell the compiler where to find the Python and pybind11 headers\n",
    "python_include = sysconfig.get_paths()['include']\n",
    "pybind11_include = pybind11.get_include()\n",
    "os.environ['CXXFLAGS'] = f\"-I{python_include} -I{pybind11_include}\"\n",
    "\n",
    "# Optional: help downstream tools pick the right interpreter\n",
    "os.environ['PYTHON_EXECUTABLE'] = sys.executable\n",
    "\n",
    "# Now Vitis\n",
    "os.environ[\"XILINX_VITIS\"] = \"/opt/tools/Xilinx/Vitis/2023.2/\"\n",
    "os.environ[\"XILINX_XRT\"] = \"/opt/xilinx/xrt/\"\n",
    "os.environ[\"XILINX_PLATFORM\"] = \"/opt/xilinx/platforms/xilinx_u55c_gen3x16_xdma_3_202210_1/xilinx_u55c_gen3x16_xdma_3_202210_1.xpfm\"\n",
    "\n",
    "os.environ[\"PATH\"] = (\n",
    "    f\"{os.environ['XILINX_VITIS']}/bin:\"\n",
    "    f\"{os.environ['XILINX_XRT']}/bin:\"\n",
    "    + os.environ[\"PATH\"]\n",
    ")\n",
    "\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = (\n",
    "    f\"{os.environ['XILINX_VITIS']}/lib/lnx64.o:\"\n",
    "    f\"{os.environ['XILINX_XRT']}/lib:\"\n",
    "    + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    ")\n",
    "\n",
    "# General Imports\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import conifer\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# enable more output from conifer\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.WARNING)\n",
    "logger = logging.getLogger('conifer')\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "seed = int('fpga_tutorial'.encode('utf-8').hex(), 16) % 2**31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce6e058-0cc4-427b-a3ff-7794d4a47bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c42ef5a2-d426-4f7f-a088-e83586e392f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "X_train = np.load('moons_dataset/X_train.npy').astype('float32')\n",
    "X_test  = np.load('moons_dataset/X_test.npy' ).astype('float32')\n",
    "Y_train = np.load('moons_dataset/y_train.npy').astype('float32')\n",
    "Y_test  = np.load('moons_dataset/y_test.npy' ).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "488d412d-c03e-425c-8363-029cfd684c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n",
      "1/2 [==============>...............] - ETA: 1s - loss: 0.3574 - accuracy: 0.8750\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.57172, saving model to model_1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.57172, saving model to model_1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 1: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 1: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "2/2 [==============================] - 2s 317ms/step - loss: 0.3498 - accuracy: 0.8731 - val_loss: 0.5717 - val_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3273 - accuracy: 0.8828\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 2: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 2: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3149 - accuracy: 0.8805 - val_loss: 0.5774 - val_accuracy: 0.8144 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2998 - accuracy: 0.8770\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 3: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 3: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.2885 - accuracy: 0.8853 - val_loss: 0.5831 - val_accuracy: 0.8256 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2822 - accuracy: 0.8877\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 4: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 4: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.2830 - accuracy: 0.8901 - val_loss: 0.5879 - val_accuracy: 0.8256 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2795 - accuracy: 0.8887\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 5: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 5: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.2682 - accuracy: 0.8944 - val_loss: 0.5917 - val_accuracy: 0.8176 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2890 - accuracy: 0.8867\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 6: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 6: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.2673 - accuracy: 0.8987 - val_loss: 0.5942 - val_accuracy: 0.8048 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2518 - accuracy: 0.9053\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 7: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 7: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.2575 - accuracy: 0.9013 - val_loss: 0.5946 - val_accuracy: 0.7952 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2654 - accuracy: 0.8916\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 8: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 8: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.2533 - accuracy: 0.9019 - val_loss: 0.5936 - val_accuracy: 0.7984 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2718 - accuracy: 0.8877\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 9: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 9: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.2516 - accuracy: 0.8971 - val_loss: 0.5914 - val_accuracy: 0.7968 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2401 - accuracy: 0.9092\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.57172\n",
      "\n",
      "Epoch 10: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 10: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 10: saving model to model_1/KERAS_check_model_epoch10.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.2450 - accuracy: 0.9061 - val_loss: 0.5876 - val_accuracy: 0.7984 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7ccc12fc40>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer=adam, loss=['binary_crossentropy'], metrics=['accuracy'])\n",
    "callbacks = all_callbacks(\n",
    "    stop_patience=1000,\n",
    "    lr_factor=0.5,\n",
    "    lr_patience=10,\n",
    "    lr_epsilon=0.000001,\n",
    "    lr_cooldown=2,\n",
    "    lr_minimum=0.0000001,\n",
    "    outputDir='model_1',\n",
    ")\n",
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=1024,\n",
    "    epochs=10,\n",
    "    validation_split=0.25,\n",
    "    shuffle=True,\n",
    "    callbacks=callbacks.callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79efcedf-d8a7-4248-9d89-4c29d9ddabfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_4 (Bat  (None, 2)                 8         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               384       \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11657 (45.54 KB)\n",
      "Trainable params: 11205 (43.77 KB)\n",
      "Non-trainable params: 452 (1.77 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create new model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28e115db-5ff7-4f1a-b773-d9e477ed3f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: input_2, layer type: InputLayer, input shapes: [[None, 2]], output shape: [None, 2]\n",
      "Layer name: batch_normalization_4, layer type: BatchNormalization, input shapes: [[None, 2]], output shape: [None, 2]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 2]], output shape: [None, 128]\n",
      "Layer name: batch_normalization_5, layer type: BatchNormalization, input shapes: [[None, 128]], output shape: [None, 128]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 128]], output shape: [None, 64]\n",
      "Layer name: batch_normalization_6, layer type: BatchNormalization, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 64]], output shape: [None, 32]\n",
      "Layer name: batch_normalization_7, layer type: BatchNormalization, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 1]\n",
      "-----------------------------------\n",
      "Configuration\n",
      "{\n",
      "  \"Model\": {\n",
      "    \"Precision\": {\n",
      "      \"default\": \"fixed<16,6>\"\n",
      "    },\n",
      "    \"ReuseFactor\": 1,\n",
      "    \"Strategy\": \"Latency\",\n",
      "    \"BramFactor\": 1000000000,\n",
      "    \"TraceOutput\": false\n",
      "  }\n",
      "}\n",
      "-----------------------------------\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: input_2, layer type: InputLayer, input shapes: [[None, 2]], output shape: [None, 2]\n",
      "Layer name: batch_normalization_4, layer type: BatchNormalization, input shapes: [[None, 2]], output shape: [None, 2]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 2]], output shape: [None, 128]\n",
      "Layer name: batch_normalization_5, layer type: BatchNormalization, input shapes: [[None, 128]], output shape: [None, 128]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 128]], output shape: [None, 64]\n",
      "Layer name: batch_normalization_6, layer type: BatchNormalization, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 64]], output shape: [None, 32]\n",
      "Layer name: batch_normalization_7, layer type: BatchNormalization, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 1]\n",
      "Creating HLS model\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='model', backend='Vitis')\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "print(json.dumps(config, indent=2))\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, hls_config=config, backend='Vitis', output_dir='model_1/hls4ml_prj', part='xc7z020clg400-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c90325e-e992-4ef6-a0dd-6a36a39a833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()\n",
    "X_test = np.ascontiguousarray(X_test)\n",
    "y_hls = hls_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c50e83ba-694b-47f6-8c43-847b8491f9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45703125],\n",
       "       [0.46484375],\n",
       "       [0.46875   ],\n",
       "       ...,\n",
       "       [0.5810547 ],\n",
       "       [0.49609375],\n",
       "       [0.5107422 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d128885-956f-4b73-9bf1-ae54a4ef4f46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2023.2 (64-bit)\n",
      "  **** SW Build 4023990 on Oct 11 2023\n",
      "  **** IP Build 4028589 on Sat Oct 14 00:45:43 MDT 2023\n",
      "  **** SharedData Build 4025554 on Tue Oct 10 17:18:54 MDT 2023\n",
      "    ** Copyright 1986-2022 Xilinx, Inc. All Rights Reserved.\n",
      "    ** Copyright 2022-2023 Advanced Micro Devices, Inc. All Rights Reserved.\n",
      "\n",
      "source /opt/tools/Xilinx/Vitis_HLS/2023.2/scripts/vitis_hls/hls.tcl -notrace\n",
      "INFO: [HLS 200-10] Running '/opt/tools/Xilinx/Vitis_HLS/2023.2/bin/unwrapped/lnx64.o/vitis_hls'\n",
      "INFO: [HLS 200-10] For user 'brivio' on host '8aaf832771b8' (Linux_x86_64 version 5.4.0-169-generic) on Thu Sep 04 14:49:59 UTC 2025\n",
      "INFO: [HLS 200-10] On os Ubuntu 24.04.2 LTS\n",
      "INFO: [HLS 200-10] In directory '/home/brivio/model_1/hls4ml_prj'\n",
      "INFO: [HLS 200-2053] The vitis_hls executable is being deprecated. Consider using vitis-run --mode hls --tcl\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-1510] Running: open_project myproject_prj \n",
      "INFO: [HLS 200-10] Opening project '/home/brivio/model_1/hls4ml_prj/myproject_prj'.\n",
      "INFO: [HLS 200-1510] Running: set_top myproject \n",
      "INFO: [HLS 200-1510] Running: add_files firmware/myproject.cpp -cflags -std=c++0x \n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject.cpp' to the project\n",
      "INFO: [HLS 200-1510] Running: add_files -tb myproject_test.cpp -cflags -std=c++0x \n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [HLS 200-1510] Running: add_files -tb firmware/weights \n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-1510] Running: add_files -tb tb_data \n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-1510] Running: open_solution solution1 \n",
      "INFO: [HLS 200-10] Opening solution '/home/brivio/model_1/hls4ml_prj/myproject_prj/solution1'.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with an uncertainty of 1.35ns.\n",
      "INFO: [HLS 200-1611] Setting target device to 'xcu250-figd2104-2L-e'\n",
      "INFO: [HLS 200-1505] Using flow_target 'vivado'\n",
      "Resolution: For help on HLS 200-1505 see docs.xilinx.com/access/sources/dita/topic?Doc_Version=2023.2%20English&url=ug1448-hls-guidance&resourceid=200-1505.html\n",
      "INFO: [HLS 200-1464] Running solution command: config_compile -name_max_length=80\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set to 80.\n",
      "INFO: [HLS 200-1464] Running solution command: config_schedule -enable_dsp_full_reg=0\n",
      "INFO: [HLS 200-1510] Running: config_array_partition -maximum_size 4096 \n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "ERROR: [HLS 200-642] The 'config_array_partition -maximum_size' command is not supported.\n",
      "INFO: [HLS 200-1510] Running: config_compile -name_max_length 80 \n",
      "INFO: [XFORM 203-1161] The maximum of name length is set to 80.\n",
      "INFO: [HLS 200-1510] Running: set_part xc7z020clg400-1 \n",
      "WARNING: [HLS 200-1610] Resetting target device to 'xc7z020-clg400-1'\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set to 80.\n",
      "INFO: [HLS 200-1510] Running: config_schedule -enable_dsp_full_reg=false \n",
      "INFO: [HLS 200-1510] Running: create_clock -period 5 -name default \n",
      "INFO: [HLS 200-1510] Running: set_clock_uncertainty 27% default \n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [HLS 200-1510] Running: csynth_design \n",
      "INFO: [HLS 200-111] Finished File checks and directory preparation: CPU user time: 0.06 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.06 seconds; current allocated memory: 286.598 MB.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... \n",
      "WARNING: [HLS 207-5536] 'Resource pragma' is deprecated, use 'bind_op/bind_storage pragma' instead (firmware/nnet_utils/nnet_dense_resource.h:33:9)\n",
      "WARNING: [HLS 207-5536] 'Resource pragma' is deprecated, use 'bind_op/bind_storage pragma' instead (firmware/nnet_utils/nnet_dense_resource.h:107:9)\n",
      "WARNING: [HLS 207-5536] 'Resource pragma' is deprecated, use 'bind_op/bind_storage pragma' instead (firmware/nnet_utils/nnet_dense_resource.h:189:9)\n",
      "WARNING: [HLS 207-5292] unused parameter 'keep' (firmware/nnet_utils/nnet_helpers.h:285:99)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:14:36)\n",
      "WARNING: [HLS 207-5292] unused parameter 'buffer' (firmware/nnet_utils/nnet_function_stubs.h:15:36)\n",
      "WARNING: [HLS 207-5292] unused parameter 'partition' (firmware/nnet_utils/nnet_function_stubs.h:16:44)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:24:24)\n",
      "WARNING: [HLS 207-5292] unused parameter 'buffer' (firmware/nnet_utils/nnet_function_stubs.h:25:24)\n",
      "WARNING: [HLS 207-5292] unused parameter 'partition' (firmware/nnet_utils/nnet_function_stubs.h:26:32)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:33:30)\n",
      "WARNING: [HLS 207-5292] unused parameter 'res' (firmware/nnet_utils/nnet_function_stubs.h:33:58)\n",
      "WARNING: [HLS 207-5292] unused parameter 'weights' (firmware/nnet_utils/nnet_function_stubs.h:34:51)\n",
      "WARNING: [HLS 207-5292] unused parameter 'biases' (firmware/nnet_utils/nnet_function_stubs.h:35:49)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:42:30)\n",
      "WARNING: [HLS 207-5292] unused parameter 'res' (firmware/nnet_utils/nnet_function_stubs.h:42:58)\n",
      "WARNING: [HLS 207-5292] unused parameter 'weights' (firmware/nnet_utils/nnet_function_stubs.h:43:51)\n",
      "WARNING: [HLS 207-5292] unused parameter 'biases' (firmware/nnet_utils/nnet_function_stubs.h:44:49)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_function_stubs.h:51:29)\n",
      "WARNING: [HLS 207-5292] unused parameter 'res' (firmware/nnet_utils/nnet_function_stubs.h:51:80)\n",
      "WARNING: [HLS 207-5292] unused parameter 'weights' (firmware/nnet_utils/nnet_function_stubs.h:52:50)\n",
      "WARNING: [HLS 207-5292] unused parameter 'biases' (firmware/nnet_utils/nnet_function_stubs.h:53:48)\n",
      "WARNING: [HLS 207-5292] unused parameter 'data' (firmware/nnet_utils/nnet_code_gen.h:16:39)\n",
      "WARNING: [HLS 207-5292] unused parameter 'res' (firmware/nnet_utils/nnet_code_gen.h:17:38)\n",
      "WARNING: [HLS 207-5292] unused parameter 'weights' (firmware/nnet_utils/nnet_code_gen.h:18:60)\n",
      "WARNING: [HLS 207-5292] unused parameter 'biases' (firmware/nnet_utils/nnet_code_gen.h:19:58)\n",
      "INFO: [HLS 200-111] Finished Source Code Analysis and Preprocessing: CPU user time: 10.07 seconds. CPU system time: 1.32 seconds. Elapsed time: 11.75 seconds; current allocated memory: 292.172 MB.\n",
      "INFO: [HLS 200-777] Using interface defaults for 'Vivado' flow target.\n",
      "INFO: [HLS 200-1995] There were 5,362 instructions in the design after the 'Compile/Link' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 667,931 instructions in the design after the 'Unroll/Inline' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 194,553 instructions in the design after the 'Unroll/Inline (step 2)' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 194,504 instructions in the design after the 'Unroll/Inline (step 3)' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 193,848 instructions in the design after the 'Unroll/Inline (step 4)' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 140,134 instructions in the design after the 'Array/Struct' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 107,375 instructions in the design after the 'Array/Struct (step 2)' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 107,375 instructions in the design after the 'Array/Struct (step 3)' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 107,379 instructions in the design after the 'Array/Struct (step 4)' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 107,373 instructions in the design after the 'Array/Struct (step 5)' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 106,987 instructions in the design after the 'Performance' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 105,831 instructions in the design after the 'Performance (step 2)' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 105,831 instructions in the design after the 'Performance (step 3)' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 105,831 instructions in the design after the 'Performance (step 4)' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 105,833 instructions in the design after the 'HW Transforms (step 1)' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "WARNING: [HLS 200-1995] There were 105,847 instructions in the design after the 'HW Transforms (step 2)' phase of compilation. See the Design Size Report for more details: /home/brivio/model_1/hls4ml_prj/myproject_prj/solution1/syn/report/csynth_design_size.rpt\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config2::scale_t*, config2::bias_t*)' (firmware/nnet_utils/nnet_batchnorm.h:54:25)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config3::weight_t*, config3::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:42:27)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::DenseLatency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>::dense(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' into 'void nnet::dense<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config3::weight_t*, config3::bias_t*)' (firmware/nnet_utils/nnet_dense.h:45:2)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config5::scale_t*, config5::bias_t*)' (firmware/nnet_utils/nnet_batchnorm.h:54:25)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config6::weight_t*, config6::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:42:27)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::DenseLatency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>::dense(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' into 'void nnet::dense<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config6::weight_t*, config6::bias_t*)' (firmware/nnet_utils/nnet_dense.h:45:2)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config8::scale_t*, config8::bias_t*)' (firmware/nnet_utils/nnet_batchnorm.h:54:25)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config9::weight_t*, config9::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:42:27)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::DenseLatency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>::dense(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' into 'void nnet::dense<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config9::weight_t*, config9::bias_t*)' (firmware/nnet_utils/nnet_dense.h:45:2)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config11::scale_t*, config11::bias_t*)' (firmware/nnet_utils/nnet_batchnorm.h:54:25)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>)' into 'void nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config12::weight_t*, config12::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:42:27)\n",
      "INFO: [HLS 214-131] Inlining function 'nnet::DenseLatency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>::dense(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' into 'void nnet::dense<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config12::weight_t*, config12::bias_t*)' (firmware/nnet_utils/nnet_dense.h:45:2)\n",
      "INFO: [HLS 214-131] Inlining function 'void nnet::dense<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config3::weight_t*, config3::bias_t*)' into 'myproject(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (firmware/myproject.cpp:52:2)\n",
      "INFO: [HLS 214-131] Inlining function 'void nnet::dense<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config6::weight_t*, config6::bias_t*)' into 'myproject(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (firmware/myproject.cpp:64:2)\n",
      "INFO: [HLS 214-131] Inlining function 'void nnet::dense<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config9::weight_t*, config9::bias_t*)' into 'myproject(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (firmware/myproject.cpp:76:2)\n",
      "INFO: [HLS 214-131] Inlining function 'void nnet::dense<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config12::weight_t*, config12::bias_t*)' into 'myproject(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*)' (firmware/myproject.cpp:88:2)\n",
      "INFO: [HLS 214-291] Loop 'VITIS_LOOP_114_1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_activation.h:114:23)\n",
      "INFO: [HLS 214-291] Loop 'Result' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:64:5)\n",
      "INFO: [HLS 214-291] Loop 'Accum1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:54:5)\n",
      "INFO: [HLS 214-291] Loop 'Accum2' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:56:9)\n",
      "INFO: [HLS 214-291] Loop 'ResetAccum' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:48:5)\n",
      "INFO: [HLS 214-291] Loop 'Product1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:37:5)\n",
      "INFO: [HLS 214-291] Loop 'Product2' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_dense_latency.h:40:9)\n",
      "INFO: [HLS 214-291] Loop 'Result' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_batchnorm.h:52:5)\n",
      "INFO: [HLS 214-291] Loop 'VITIS_LOOP_43_1' is marked as complete unroll implied by the pipeline pragma (firmware/nnet_utils/nnet_activation.h:43:22)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_114_1' (firmware/nnet_utils/nnet_activation.h:114:23) in function 'nnet::sigmoid<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, sigmoid_config13>' completely with a factor of 1 (firmware/nnet_utils/nnet_activation.h:95:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:64:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' completely with a factor of 1 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:54:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' completely with a factor of 32 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:56:9) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' completely with a factor of 1 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:48:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' completely with a factor of 1 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' completely with a factor of 32 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:40:9) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' completely with a factor of 1 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_batchnorm.h:52:5) in function 'nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 32 (firmware/nnet_utils/nnet_batchnorm.h:33:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_43_1' (firmware/nnet_utils/nnet_activation.h:43:22) in function 'nnet::relu<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, relu_config10>' completely with a factor of 32 (firmware/nnet_utils/nnet_activation.h:39:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:64:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 32 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:54:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 64 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:56:9) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 32 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:48:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 32 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 64 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:40:9) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' completely with a factor of 32 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_batchnorm.h:52:5) in function 'nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' completely with a factor of 64 (firmware/nnet_utils/nnet_batchnorm.h:33:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_43_1' (firmware/nnet_utils/nnet_activation.h:43:22) in function 'nnet::relu<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, relu_config7>' completely with a factor of 64 (firmware/nnet_utils/nnet_activation.h:39:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:64:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 64 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:54:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 128 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:56:9) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 64 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:48:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 64 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 128 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:40:9) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' completely with a factor of 64 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_batchnorm.h:52:5) in function 'nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 128 (firmware/nnet_utils/nnet_batchnorm.h:33:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'VITIS_LOOP_43_1' (firmware/nnet_utils/nnet_activation.h:43:22) in function 'nnet::relu<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, relu_config4>' completely with a factor of 128 (firmware/nnet_utils/nnet_activation.h:39:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:64:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 128 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:54:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 2 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:56:9) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 128 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:48:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 128 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:37:5) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 2 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:40:9) in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>' completely with a factor of 128 (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-186] Unrolling loop 'Result' (firmware/nnet_utils/nnet_batchnorm.h:52:5) in function 'nnet::normalize<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 2 (firmware/nnet_utils/nnet_batchnorm.h:33:0)\n",
      "INFO: [HLS 214-178] Inlining function 'std::enable_if<!(std::is_same<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_uint<1> >::value), ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::type nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>(config9::accum_t)' into 'void nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config9::weight_t*, config9::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-178] Inlining function 'std::enable_if<!(std::is_same<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_uint<1> >::value), ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::type nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>(config12::accum_t)' into 'void nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config12::weight_t*, config12::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:15:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b12': Complete partitioning on dimension 1. (firmware/weights/b12.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b11': Complete partitioning on dimension 1. (firmware/weights/b11.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 's11': Complete partitioning on dimension 1. (firmware/weights/s11.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b9': Complete partitioning on dimension 1. (firmware/weights/b9.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b8': Complete partitioning on dimension 1. (firmware/weights/b8.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 's8': Complete partitioning on dimension 1. (firmware/weights/s8.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b6': Complete partitioning on dimension 1. (firmware/weights/b6.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b5': Complete partitioning on dimension 1. (firmware/weights/b5.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 's5': Complete partitioning on dimension 1. (firmware/weights/s5.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b3': Complete partitioning on dimension 1. (firmware/weights/b3.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'b2': Complete partitioning on dimension 1. (firmware/weights/b2.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 's2': Complete partitioning on dimension 1. (firmware/weights/s2.h:12:0)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'mult': Complete partitioning on dimension 1. (firmware/nnet_utils/nnet_dense_latency.h:17:32)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer2_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:46:11)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer3_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:50:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer4_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:54:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer5_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:58:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer6_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:62:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer7_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:66:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer8_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:70:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer9_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:74:14)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer10_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:78:15)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer11_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:82:15)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer12_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:86:15)\n",
      "INFO: [HLS 214-248] Applying array_partition to 'layer13_out': Complete partitioning on dimension 1. (firmware/myproject.cpp:10:0)\n",
      "INFO: [HLS 214-248] Applying array_reshape to 'input_2': Complete reshaping on dimension 1. (firmware/myproject.cpp:10:0)\n",
      "INFO: [HLS 214-364] Automatically inlining function 'std::enable_if<!(std::is_same<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_uint<1> >::value), ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::type nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>(config3::accum_t)' to improve effectiveness of pipeline pragma in function 'void nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config3>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config3::weight_t*, config3::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:66:21)\n",
      "INFO: [HLS 214-364] Automatically inlining function 'std::enable_if<!(std::is_same<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_uint<1> >::value), ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::type nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>(config6::accum_t)' to improve effectiveness of pipeline pragma in function 'void nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>(ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>*, config6::weight_t*, config6::bias_t*)' (firmware/nnet_utils/nnet_dense_latency.h:66:21)\n",
      "INFO: [HLS 200-111] Finished Compiling Optimization and Transform: CPU user time: 473.76 seconds. CPU system time: 3.49 seconds. Elapsed time: 478.17 seconds; current allocated memory: 303.699 MB.\n",
      "INFO: [HLS 200-111] Finished Checking Pragmas: CPU user time: 0 seconds. CPU system time: 0 seconds. Elapsed time: 0 seconds; current allocated memory: 303.699 MB.\n",
      "INFO: [HLS 200-10] Starting code transformations ...\n",
      "INFO: [HLS 200-111] Finished Standard Transforms: CPU user time: 1.92 seconds. CPU system time: 0.06 seconds. Elapsed time: 1.99 seconds; current allocated memory: 365.137 MB.\n",
      "INFO: [HLS 200-10] Checking synthesizability ...\n",
      "INFO: [HLS 200-111] Finished Checking Synthesizability: CPU user time: 2.44 seconds. CPU system time: 0.01 seconds. Elapsed time: 2.46 seconds; current allocated memory: 372.336 MB.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation.h:115:31) to (firmware/nnet_utils/nnet_activation.h:123:1) in function 'nnet::sigmoid<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, sigmoid_config13>'... converting 3 basic blocks.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config9>' (firmware/nnet_utils/nnet_dense_latency.h:33:27)...2043 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6>' (firmware/nnet_utils/nnet_mult.h:33:11)...8179 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config12>' (firmware/nnet_utils/nnet_dense_latency.h:33:1)...32 expression(s) balanced.\n",
      "INFO: [HLS 200-111] Finished Loop, function and other optimizations: CPU user time: 6.78 seconds. CPU system time: 0.03 seconds. Elapsed time: 6.82 seconds; current allocated memory: 481.516 MB.\n",
      "INFO: [HLS 200-111] Finished Architecture Synthesis: CPU user time: 9.57 seconds. CPU system time: 0.13 seconds. Elapsed time: 9.7 seconds; current allocated memory: 812.016 MB.\n",
      "INFO: [HLS 200-10] Starting hardware synthesis ...\n",
      "INFO: [HLS 200-10] Synthesizing 'myproject' ...\n",
      "WARNING: [SYN 201-103] Legalizing function name 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2>' to 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3>' to 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config4>' to 'relu_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_relu_config4_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config5>' to 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config5_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config6>' to 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config7>' to 'relu_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_relu_config7_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config8>' to 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config8_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config9>' to 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config9_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config10>' to 'relu_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_relu_config10_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>' to 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config11_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config12>' to 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config12_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'sigmoid<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, sigmoid_config13>' to 'sigmoid_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_sigmoid_config13_s'.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 3, function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.33 seconds. CPU system time: 0.07 seconds. Elapsed time: 0.41 seconds; current allocated memory: 816.246 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.03 seconds. CPU system time: 0 seconds. Elapsed time: 0.03 seconds; current allocated memory: 816.246 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 4, function 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config3>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 1.18 seconds. CPU system time: 0.01 seconds. Elapsed time: 1.19 seconds; current allocated memory: 826.348 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.39 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.39 seconds; current allocated memory: 830.324 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_relu_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'relu<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config4>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'relu<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config4>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.35 seconds. CPU system time: 0 seconds. Elapsed time: 0.36 seconds; current allocated memory: 833.852 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.1 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.11 seconds; current allocated memory: 833.852 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config5>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 3, function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config5>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.82 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.83 seconds; current allocated memory: 839.449 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.2 seconds. CPU system time: 0 seconds. Elapsed time: 0.2 seconds; current allocated memory: 843.566 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config6>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 10, function 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config6>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 64.47 seconds. CPU system time: 0.26 seconds. Elapsed time: 64.8 seconds; current allocated memory: 1.127 GB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 395.75 seconds. CPU system time: 5.54 seconds. Elapsed time: 401.42 seconds; current allocated memory: 5.569 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_relu_config7_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'relu<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config7>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'relu<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config7>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 3.63 seconds. CPU system time: 0.13 seconds. Elapsed time: 3.76 seconds; current allocated memory: 5.569 GB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.06 seconds. CPU system time: 0 seconds. Elapsed time: 0.06 seconds; current allocated memory: 5.569 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config8>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 3, function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config8>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.38 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.39 seconds; current allocated memory: 5.569 GB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.09 seconds. CPU system time: 0 seconds. Elapsed time: 0.08 seconds; current allocated memory: 5.569 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config9>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 9, function 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config9>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 10.24 seconds. CPU system time: 0.02 seconds. Elapsed time: 10.28 seconds; current allocated memory: 5.569 GB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 27.09 seconds. CPU system time: 0.28 seconds. Elapsed time: 27.4 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_relu_config10_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'relu<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config10>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 1, function 'relu<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, relu_config10>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 1 seconds. CPU system time: 0.05 seconds. Elapsed time: 1.05 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.04 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.04 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 3, function 'normalize<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.21 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.22 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.05 seconds. CPU system time: 0 seconds. Elapsed time: 0.06 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config12_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config12>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 8, function 'dense_latency<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config12>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.21 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.22 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.06 seconds. CPU system time: 0 seconds. Elapsed time: 0.06 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'sigmoid_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_sigmoid_config13_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'sigmoid<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, sigmoid_config13>'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 5, function 'sigmoid<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, sigmoid_config13>'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.07 seconds. CPU system time: 0 seconds. Elapsed time: 0.07 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.04 seconds. CPU system time: 0 seconds. Elapsed time: 0.03 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'myproject' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'myproject'.\n",
      "INFO: [HLS 200-1470] Pipelining result : Target II = NA, Final II = 1, Depth = 59, function 'myproject'\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111] Finished Scheduling: CPU user time: 0.25 seconds. CPU system time: 0.01 seconds. Elapsed time: 0.25 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111] Finished Binding: CPU user time: 0.48 seconds. CPU system time: 0 seconds. Elapsed time: 0.48 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_12ns_26_2_0': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 0.99 seconds. CPU system time: 0.02 seconds. Elapsed time: 1.02 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-104] Estimated max fanout for 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s' is 5249 from HDL expression: ((1'b1 == ap_ce_reg) & (1'b0 == ap_block_pp0_stage0_11001))\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_5ns_21_2_0': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_5s_21_2_0': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_6ns_22_2_0': 4 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_6s_22_2_0': 2 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_7ns_23_2_0': 11 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_7s_23_2_0': 11 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_8ns_24_2_0': 25 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_8s_24_2_0': 16 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_9ns_25_2_0': 49 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_9s_25_2_0': 49 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config3_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 1 seconds. CPU system time: 0.01 seconds. Elapsed time: 1.03 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'relu_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_relu_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'relu_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_relu_config4_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 1.13 seconds. CPU system time: 0.03 seconds. Elapsed time: 1.17 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_12ns_26_2_0': 127 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'normalize_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config5_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 3.12 seconds. CPU system time: 0.01 seconds. Elapsed time: 3.14 seconds; current allocated memory: 5.757 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-104] Estimated max fanout for 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_s' is 255914 from HDL expression: ((1'b0 == ap_block_pp0_stage0_11001) & (1'b1 == ap_ce_reg))\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_5ns_21_2_0': 40 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_5s_21_2_0': 32 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_6ns_22_2_0': 146 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_6s_22_2_0': 167 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_7ns_23_2_0': 457 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_7s_23_2_0': 432 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_8ns_24_2_0': 1050 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_8s_24_2_0': 1080 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_9ns_25_2_0': 982 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'mul_16s_9s_25_2_0': 1035 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_latency_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_s'.\n",
      "INFO: [HLS 200-111] Finished Creating RTL model: CPU user time: 29.14 seconds. CPU system time: 0.03 seconds. Elapsed time: 29.19 seconds; current allocated memory: 5.757 GB.\n"
     ]
    }
   ],
   "source": [
    "hls_model.build(csim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf6665f-94a7-41ed-a19a-bafd3fd81897",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report('model_1/hls4ml_prj/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfcaabe-683d-405d-be23-60e525a7539b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (fpga-ml)",
   "language": "python",
   "name": "fpga-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
